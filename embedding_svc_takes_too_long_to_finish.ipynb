{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61e0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import cohen_kappa_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d66e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sigcse_2024.csv')\n",
    "\n",
    "train_df = df[df.subset == 'train'].copy()\n",
    "test_df = df[df.subset == 'test'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4181467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_names = ['bert_base', 'bert_large', 'sbert',\n",
    "                   'gpt2', 'gpt2_medium', 'gpt2_large', 'gpt2_xl',\n",
    "                   'llama_7b', 'llama_13b', 'llama_30b', 'llama_65b',\n",
    "                   'llama2_7b', 'llama2_13b', 'llama2_70b',\n",
    "                   'llama2_7b_chat', 'llama2_13b_chat', 'llama2_70b_chat',\n",
    "                   'vicuna_7b', 'vicuna_13b', 'vicuna_33b']\n",
    "embedding_modes = ['last_token', 'mean_pooling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6d9490",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf']\n",
    "cs = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d843d08a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_last_token\n",
      "poly_1\n",
      "poly_2\n",
      "poly_4\n",
      "poly_8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2007\u001b[0m, in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2007\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m sub_validate_df \u001b[38;5;241m=\u001b[39m fold_dfs[i]\n\u001b[1;32m     18\u001b[0m svc \u001b[38;5;241m=\u001b[39m SVC(kernel\u001b[38;5;241m=\u001b[39mkernel, C\u001b[38;5;241m=\u001b[39mc)\n\u001b[0;32m---> 20\u001b[0m train_X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(sub_train_df), \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     21\u001b[0m train_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(sub_train_df), ), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     23\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2009\u001b[0m, in \u001b[0;36mshape\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2007\u001b[0m     result \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m-> 2009\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_to_config_to_metrics = {}\n",
    "\n",
    "for embedding in list(map(lambda x : f'{x[0]}_{x[1]}', list(itertools.product(embedding_names, embedding_modes)))) + ['openai_api']:\n",
    "    print(f'{embedding}')\n",
    "    embeddings = pickle.load(open(f'embeddings/{embedding}.pkl', 'rb'))\n",
    "    \n",
    "    config_to_metrics = {}\n",
    "    for kernel in kernels:\n",
    "        for c in cs:\n",
    "            print(f'{kernel}_{c}')\n",
    "            for qid, qid_df in train_df.groupby('qid'):\n",
    "                fold_dfs = np.array_split(qid_df.sample(frac=1., random_state=64), 5)\n",
    "\n",
    "                for i in range(5):\n",
    "                    sub_train_df = pd.concat(fold_dfs[:i] + fold_dfs[i + 1:])\n",
    "                    sub_validate_df = fold_dfs[i]\n",
    "\n",
    "                    svc = SVC(kernel=kernel, C=c)\n",
    "\n",
    "                    train_X = np.zeros((len(sub_train_df), np.shape(embeddings)[1]))\n",
    "                    train_y = np.zeros((len(sub_train_df), ), dtype=int)\n",
    "\n",
    "                    index = 0\n",
    "                    for row_index, row in sub_train_df.iterrows():\n",
    "                        train_X[index, :] = embeddings[row_index]\n",
    "                        train_y[index] = row.binary_ground_truth\n",
    "\n",
    "                        index += 1\n",
    "\n",
    "                    svc.fit(train_X, train_y)\n",
    "\n",
    "                    validate_X = np.zeros((len(sub_validate_df), np.shape(embeddings)[1]))\n",
    "                    validate_y = np.zeros((len(sub_validate_df), ), dtype=int)\n",
    "\n",
    "                    index = 0\n",
    "                    for row_index, row in sub_validate_df.iterrows():\n",
    "                        validate_X[index, :] = embeddings[row_index]\n",
    "                        validate_y[index] = row.binary_ground_truth\n",
    "\n",
    "                        index += 1\n",
    "\n",
    "                    predicted = svc.predict(validate_X)\n",
    "\n",
    "                    train_df.loc[sub_validate_df.index, 'predicted'] = predicted\n",
    "            \n",
    "            accuracy = len(train_df[train_df.binary_ground_truth == train_df.predicted])/len(train_df)\n",
    "            kappa = cohen_kappa_score(train_df.binary_ground_truth, train_df.predicted)\n",
    "            f1 = f1_score(train_df.binary_ground_truth, train_df.predicted)\n",
    "        \n",
    "            config_to_metrics[f'{kernel}_{c}'] = accuracy, kappa, f1\n",
    "    \n",
    "    embedding_to_config_to_metrics[embedding] = config_to_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8f815",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(embedding_to_config_to_metrics, open('embedding_to_config_to_metrics.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_to_best_config = {}\n",
    "embedding_to_metrics = {}\n",
    "for embedding in embedding_to_config_to_metrics:\n",
    "    config_to_metrics = embedding_to_config_to_metrics[embedding]\n",
    "    \n",
    "    best_configs = [max(config_to_metrics, key=lambda x : config_to_metrics.get(x)[i]) for i in range(3)]\n",
    "    assert len(set(best_configs)) == 1\n",
    "    \n",
    "    print(embedding)\n",
    "    print(best_configs[0])\n",
    "    \n",
    "    embedding_to_best_config[embedding] = best_configs[0]\n",
    "    embedding_to_metrics[embedding] = config_to_metrics[best_configs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfba711",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_embeddings = [max(embedding_to_metrics, key=lambda x : embedding_to_metrics.get(x)[i]) for i in range(3)]\n",
    "assert len(set(best_embeddings)) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd24731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embeddings = pickle.load(open(f'embeddings/{best_embeddings[0]}.pkl', 'rb'))\n",
    "\n",
    "best_config = embedding_to_best_config[best_embeddings[0]]\n",
    "\n",
    "test_df['embedding_svc'] = 0\n",
    "for qid, sub_train_df in train_df.groupby('qid'):\n",
    "    svc = SVC(kernel=best_config.split('_')[0], C=int(best_config.split('_')[1]))\n",
    "    \n",
    "    train_X = np.zeros((len(sub_train_df), np.shape(embeddings)[1]))\n",
    "    train_y = np.zeros((len(sub_train_df), ), dtype=int)\n",
    "    index = 0\n",
    "    for row_index, row in sub_train_df.iterrows():\n",
    "        train_X[index, :] = embeddings[row_index]\n",
    "        train_y[index] = row.binary_ground_truth\n",
    "\n",
    "        index += 1\n",
    "\n",
    "    svc.fit(train_X, train_y)\n",
    "    \n",
    "    sub_test_df = test_df[test_df.qid == qid]\n",
    "    \n",
    "    test_X = np.zeros((len(sub_test_df), np.shape(embeddings)[1]))\n",
    "    test_y = np.zeros((len(sub_test_df), ), dtype=int)\n",
    "    index = 0\n",
    "    for row_index, row in sub_test_df.iterrows():\n",
    "        test_X[index, :] = embeddings[row_index]\n",
    "        test_y[index] = row.binary_ground_truth\n",
    "\n",
    "        index += 1\n",
    "    \n",
    "    targets = np.array(test_y)\n",
    "    predicted = svc.predict(test_X)\n",
    "    \n",
    "    test_df.loc[sub_test_df.index, 'embedding_svc'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a8935",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(list(test_df.bigram_lr), open('embedding_svc.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
